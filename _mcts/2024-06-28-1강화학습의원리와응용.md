---
layout: single
title: "강화학습의원리와응용"
categories: 파이썬으로 만드는 인공지능
tag: [MCTS]
---

# 9장 강화학습과 게임지능

## 9.1 강화학습의 원리와 응용

### 9.1.1 multi armed bandit


1. multi armed bandit
    - 여러 손잡이 중 하나를 선택해 1달러를 넣고 당김
    - 결과는 0달러 or 2달러 (-1, +1)
    - 손잡이에서 돈을 딸 확률은 숨겨져 있는 상태

2. 문제 설정
    - 행동에 따라 보상이 주어지는 문제
    - 행동 : 여러 개의 손잡이 중 1개를 고르는 일, {0, 1, 2, 3, 4, ...}
    - 보상 : {-1, +1}

3. 단순성
    - state가 없는 문제 = 행동해도 환경, 확률이 변하지 않음을 의미
    - 비디오 게임, 자율주행차 등은 행동에 따라 state가 변함
    - 강화학습 중 행동, 보상만 있는 매우 기초적인 문제


4. 2가지 행동 정책
    1. random policy
        - 처음부터 끝까지 손잡이를 무작위로 선택
        - 이전 경험을 사용하지 않는 비효율적인 방법
        - 랜덤 정책을 쓰는 algorithm

    2. exploration
        - 몇 번 시도해보고 이후에는 가장 높은 확률을 보인 손잡이만 계속 당김
        - 확률이 더 높은 손잡이를 놓칠 위험
        - 입실론-탐욕 algorithm

- 강화학습에서는 2가지 정책 사이의 균형을 잡는 것이 매우 중요(비율 정하여 결정)


5. 문제 해결에 대한 고찰
    - episode : 게임을 시작하고 연속으로 행동을 취하여 마칠 때까지의 기록
    - 단순한 문제이기 때문에 episode를 충분히 길게 하여 최적 policy를 찾을 수 있음

6. random policy를 쓰는 algorithm


7. greedy algorithm
    - 과거와 미래를 전혀 고려하지 않고 현재 순간의 정보만으로 선택
    - ϵ-greedy algorithm : ϵ 비율만큼 탐험을 적용하여 탐험(random)과 탐사(greedy)의 균형을 추구
    - 탐사 : 현재까지 파악한 승리 확률에 따라 행동을 선택, 탐험 : random
    - 탐사 + ϵ 탐험


8. monte carlo method
    - 수학적 현상을 난수를 생성하여 시뮬레이션하는 기법
    - 앞선 python code는 bandit 기계의 동작을 난수를 생성하여 simulation했기 때문에 monte carlo 방법에 속한다.





### 9.1.2 gym library of OpenAI
- 주로 강화학습을 구현할 때 사용하는 library
- gym library에서 제공하는 강화학습 문제 
    1. FrozenLake
        - 출발점 S, 도착점 G, 함정 H, 길 F
        - S에서 G로 이동, F위만 이동가능
        - 각 부분이 H, F 중 어느 것인지 알려주지 않음
    2. CartPole
        - 막대가 좌우 중심을 찾는 문제
    3. MoutainCar
        - 왼쪽 언덕으로 올라간 뒤 이를 이용해 오른쪽 언덕을 넘는 문제
    4. FetchSlide
        - 로봇 손이 검정 공을 쳐서 빨간 지점까지 옮기는 문제ㅔ
    5. 아타리
        - 고전 게임...?


### 9.1.3 계산 모형

1. 강화학습의 수학 모델
    - 환경 : 상태의 종류, 행동의 종류, 보상의 종류 - MDP(Markov Decision Process)
    - agent : 환경이 제공하는 상태와 보상에 따라 행동을 취함 - Policy

2. 보상이 주어지는 시점
    - 행동을 취하고 즉시 보상이 주어지는 경우
    - 지연된 보상(바둑, 장기) - 중간 과정에서는 보상이 없고 최종 결과에만 보상이 있는 경우

3. 상태 전이
    - 결정론적 환경 : $P(s',r | s,a) = 1.0$
        - 행동에 따라 새로운 상태가 100% 정해져 있는 환경
    - stochastic 환경 : $P(s',r | s,a)$
        - 행동에 따라 새로운 상태가 정해져 있지 않은 환경

