---
layout: single
title: "istio addon 설치 (kiali)"
categories: open source
tag: [gerrit]
---

            aimlfw의 pod들이 어떻게 상호작용하는지 관찰하기 위해 시각화 tool을 설치해보려고 한다.
            istio의 addon들은 istio를 설치하면서 사용한 directory의 sample/addon에서 쉽게 설치되며, istio-system namespace에 설치된다.



## Addon
1. Grafana
    - 메트릭 데이터를 시각화하고 분석하는 데 사용
    - Prometheus와 같은 데이터 소스에서 데이터를 가져와 대시보드를 통해 다양한 지표를 시각적으로 표현
    - `kubectl -n istio-system port-forward svc/grafana 3000:3000`

2. Jaeger
    - 분산 트레이싱 시스템
    - 마이크로서비스 아키텍처에서 서비스 간 요청(traffic)의 흐름을 추적
    - `kubectl -n istio-system port-forward svc/jaeger-collector 14268:14268`

3. Kiali
    - Istio 서비스 메쉬의 관찰성을 제공
    - 서비스 간의 상호작용을 시각화하고 트래픽 흐름, 성능 등을 모니터링할 수 있는 대시보드를 제공
    - Grafana와 사용하면 더욱 상세한 metric을 시각화할 수 있음
    - 분산 추척 도구인 Jaeger와 통합하여 사용할 수 있음
    - `kubectl -n istio-system port-forward svc/kiali 20001:20001`

4. Loki
    - Loki는 로그 데이터를 수집하고 분석하는 데 사용
    - Grafana와 연동하여 로그 데이터를 시각화
    - `kubectl -n istio-system port-forward svc/loki 3100:3100`

5. Prometheus
    - 모니터링 및 경고 시스템
    - 메트릭 데이터를 수집하고 저장
    - Grafana와 함께 사용하여 대시보드를 생성
    - `kubectl -n istio-system port-forward svc/prometheus 9090:9090`


## Addon 설치
1. istio directory 이동
2. 설치 : `kubectl apply -f samples/addons/<addon_name>.yaml`
3. console 접근 : `kubectl port-forward -n istio-system svc/<svc_name> 20001:20001`




## kiali 설정

1. Envoy 사이드카 프록시 설정
    - istio는 각 service pod에 Envoy라는 proxy를 자동으로 주입하여 service 간의 traffic을 가로채고 제어함
    - 사이드카 proxy는 각 pod에 함께 배포되는 작은 proxy container, 해당 pod에서 나가는 모든 traffic을 가로챔
    - 관찰을 원하는 pod마다 사이드카 프록시를 주입해주어야함.
    
    0. istioctl 설치
        - install 다운로드 
            - `curl -L https://istio.io/downloadIstio | sh -`
        - 전역에서 사용할 수 있도록 설정
            - `nano source ~/.bashrc`
            - `export PATH=$PATH:~/istio-<version>/bin` 적고 저장
            - `source ~/.bashrc`
        - 전역에서 확인
            - `istioctl version`
        - 다운로드
            - `istioctl install --set profile=demo -y`
        - 확인
            - `kubectl get po -n istio-system`


    1. istio-operator.yaml 생성
        - 생성 directory : istio-1.22.3/manifests/profiles/
        - ```yaml
            apiVersion: install.istio.io/v1alpha1
            kind: IstioOperator
            spec: 
              profile: default
              components:
                base:
                  enabled: true
                pilot:
                  enabled: true
                ingressGateways:
                  - name: istio-ingressgateway
                    enabled: true
                values:
                  sidecarInjectorWebhook:
                    enableNamespacesByDefault: true  # 이 부분이 전역적으로 사이드카 주입을 활성화하는 설정입니다
            ```
        - 이 방법은 생성되는 모든 pod에 사이드카 프록시를 주입함.
        - istio는 전체를 재설치하는 것이 아닌, 필요한 부분을 업데이트하기 때문에 다른 설정이 변하진 않음

    2. istio 구성 업데이트
        - `istioctl install -f istio-operator.yaml -y`
        - <img  src="/assets/posts/ossca/10.png" alt=""/>

    3. namespace마다 pod 재배포
        - ```bash
            for ns in $(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}'); do
                kubectl rollout restart deployment -n $ns
            done
            ```
    4. 사이드카 주입 확인
        - 각 pod의 container로 사이드카 프록시가 주입되며, 이를 다음 명령어로 확인할 수 있다.
        - `kubectl get pods -n <namespace> -o jsonpath='{.items[*].spec.containers[*].name}'`


2. 갑자기 pod 재배포 과정에서 influxdb의 deployment의 설정 yaml의 replicas가 2로 변경되어있다... 변경해줘야겠다.

    1. `kubectl get deployment my-release-influxdb -o yaml > influxdb-deployment.yaml`

    2. spec의 replicas를 1로 변경

    3. `kubectl apply -f influxdb-deployment.yaml`

    4. 이거 왜 수정안되지.....  일단 정상작동되는거 같아서 놔두려고한다.

    5. 아하. 사이드카 프록시를 주입하고 deployment를 재배포해주면 아예 다른 deployment가 재생성된다. 다른 deployment는 최근껄로 변경됬는데 이것만 인식을 못하고 있어서 재부팅하니까 됐다.

    6. 근데 그냥 전역 설치 안하고 namespace 별로 사이드카 프록시 주입하는게 안전할 것 같다. argocd 하다가 문제가 생긴 것같다.


3. Envoy 사이드카 프록시 namespace별 설정.
    - 해당 namespace에 label을 설정해주면 istio가 모든 pod의 사이드카 프록시를 자동으로 주입한다.

    1. ns별로 사이드카 프록시 생성
        - `kubectl label namespace <namespace> istio-injection=enabled`
        - lable 확인 : `kubectl get namespace <namespace> --show-labels`

    2. deployment 재배포
        - `kubectl rollout restart deployment -n <namespace>`

    3. sidecar proxy 확인 방법
        - pod 내부에 컨테이너 목록 호출하여 사이드카 프록시 관련 컨테이너 서치
            - `kubectl get pod <pod> -n <namespace> -o jsonpath='{.spec.containers[*].name}' `
        - istio의 sidecar 삽입 웹훅 설정 확인
            - `kubectl get mutatingwebhookconfigurations istio-sidecar-injector`

4. 설치는 완료 됬는데  sidecar proxy로 인해 원래 pod들이 작동을 안하는 부분이 있어 코드 수준 혹은 네트워크 수준에서 해결해봐야할 것 같다. 이 부분에 대해서는 따로 해야겠다.